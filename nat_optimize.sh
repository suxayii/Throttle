#!/usr/bin/env bash
# =========================================================
# NAT 服务器专用优化脚本 (LXC/容器友好版)
# 基于 net-tune-pro-v3 架构精简
# 功能：增强 NAT 转发性能、优化连接跟踪、启用 BBR
# =========================================================

set -euo pipefail

# ===================== 基础配置 =====================
VERSION="1.0.0"
CONFIG_FILE="/etc/sysctl.d/99-nat-optimize.conf"
BACKUP_DIR="/root/nat-optimize-backup"
LOG_FILE="/var/log/nat-optimize.log"

# 颜色定义
RED='\033[31m'; GREEN='\033[32m'; YELLOW='\033[33m'; BLUE='\033[36m'; BOLD='\033[1m'; NC='\033[0m'

# ===================== 辅助函数 =====================
ok(){ echo -e "${GREEN}✅ $*${NC}"; }
warn(){ echo -e "${YELLOW}⚠️  $*${NC}"; }
err(){ echo -e "${RED}❌ $*${NC}"; }
info(){ echo -e "${BLUE}ℹ️  $*${NC}"; }
line(){ echo "------------------------------------------------------------"; }
cmd_exists(){ command -v "$1" >/dev/null 2>&1; }

need_root(){
  if [[ "${EUID:-$(id -u)}" -ne 0 ]]; then
    err "请使用 root 运行此脚本"
    exit 1
  fi
}

# ===================== 预检查 =====================
precheck(){
  echo
  echo -e "${BOLD}【NAT 服务器预检查】${NC}"
  line

  # 1. 虚拟化环境检测
  virt_type="unknown"
  if cmd_exists systemd-detect-virt; then
    virt_type="$(systemd-detect-virt || true)"
  elif [[ -f /.dockerenv ]] || grep -q docker /proc/1/cgroup; then
    virt_type="docker"
  fi

  if [[ "$virt_type" =~ lxc|docker|openvz ]]; then
    warn "环境：${virt_type} 容器 (内核参数受限)"
    info "提示：部分内核参数可能无法修改，脚本将自动忽略报错"
  else
    info "环境：$virt_type (支持完整内核参数)"
  fi

  # 2. 内核与 BBR
  local kernel_ver="$(uname -r)"
  info "内核版本：$kernel_ver"
  
  if sysctl net.ipv4.tcp_congestion_control | grep -q bbr; then
    ok "BBR 已启用"
  else
    # 尝试启用 BBR (容器内通常无法加载模块，但在高版本内核宿主机上可能直接可用)
    if grep -q bbr /proc/sys/net/ipv4/tcp_available_congestion_control 2>/dev/null; then
       info "内核支持 BBR，稍后将启用"
    else
       warn "未检测到 BBR 支持 (容器需宿主机开启)"
    fi
  fi

  # 3. IP 转发状态
  if [[ "$(sysctl -n net.ipv4.ip_forward 2>/dev/null)" == "1" ]]; then
    ok "IP 转发已开启"
  else
    warn "IP 转发未开启 (将在优化时开启)"
  fi

  # 4. 连接跟踪模块
  if [[ -f /proc/net/nf_conntrack ]] || sysctl net.netfilter.nf_conntrack_max >/dev/null 2>&1; then
    ok "连接跟踪 (Conntrack) 模块已加载"
    local max="$(sysctl -n net.netfilter.nf_conntrack_max 2>/dev/null || echo 0)"
    info "当前最大连接数限制：$max"
  else
    warn "未检测到 Conntrack 模块 (NAT 必需)"
  fi
  
  line
  ok "预检查完成"
}

# ===================== 生成优化配置 =====================
generate_config(){
  # 根据内存大小动态调整 nf_conntrack_max
  # 规则: 65536 per 1GB RAM, max 2097152 (保守策略)
  local mem_kb=$(awk '/MemTotal/ {print $2}' /proc/meminfo)
  local mem_gb=$((mem_kb / 1024 / 1024))
  [[ $mem_gb -lt 1 ]] && mem_gb=1
  
  local conntrack_max=$((mem_gb * 65536))
  [[ $conntrack_max -gt 2097152 ]] && conntrack_max=2097152

  cat <<EOF
# ==============================================
# NAT Server Optimization (Generated by Script)
# ==============================================

# --- 核心转发设置 ---
net.ipv4.ip_forward = 1
net.ipv4.conf.all.route_localnet = 1
net.ipv4.conf.all.forwarding = 1
net.ipv4.conf.default.forwarding = 1
net.ipv6.conf.all.forwarding = 1
net.ipv6.conf.default.forwarding = 1

# --- 连接跟踪优化 (NAT 核心) ---
# 提高最大连接数限制
net.netfilter.nf_conntrack_max = $conntrack_max
net.nf_conntrack_max = $conntrack_max

# 缩短超时时间，加快回收 (默认 established 是 5天，太长了)
net.netfilter.nf_conntrack_tcp_timeout_established = 600
net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60
net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120
net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120

# 更激进的连接回收 (视流量类型)
net.netfilter.nf_conntrack_tcp_timeout_syn_recv = 30
net.netfilter.nf_conntrack_tcp_timeout_syn_sent = 30
net.netfilter.nf_conntrack_generic_timeout = 120  # 非TCP/UDP通用超时

# UDP 连接跟踪优化 (针对 Hysteria/QUIC 等 UDP 流量)
net.netfilter.nf_conntrack_udp_timeout = 60
net.netfilter.nf_conntrack_udp_timeout_stream = 180

# --- TCP/BBR 优化 ---
net.core.default_qdisc = fq
net.ipv4.tcp_congestion_control = bbr

# --- 防 SYN 洪水 & 连接复用 ---
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_tw_reuse = 1          # 允许 TIME_WAIT 端口复用，加速短连接
net.ipv4.tcp_fin_timeout = 15      # 缩短 FIN-WAIT-2 超时
net.ipv4.tcp_tw_recycle = 0        # 明确禁用 (已废弃/NAT不安全)

# --- 缓冲区与队列 (针对高吞吐量转发优化) ---
# 增大缓冲区以适应大流量突发 (32MB)
net.core.rmem_default = 262144
net.core.wmem_default = 262144
net.core.rmem_max = 33554432
net.core.wmem_max = 33554432
net.ipv4.tcp_rmem = 4096 87380 33554432
net.ipv4.tcp_wmem = 4096 65536 33554432
net.ipv4.udp_rmem_min = 16384
net.ipv4.udp_wmem_min = 16384
# Hysteria2/TUIC/QUIC UDP 内存压力优化
net.ipv4.udp_mem = 4096 87380 33554432

# --- 背压与队列优化 ---
net.core.netdev_max_backlog = 16384
net.core.somaxconn = 8192
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.tcp_slow_start_after_idle = 0
net.ipv4.tcp_notsent_lowat = 16384
net.ipv4.tcp_collapse_max_bytes = 1048576  # 合并小包
net.ipv4.tcp_autocorking = 1               # 自动 cork 小包
net.core.busy_poll = 50                    # 低延迟场景减少轮询延迟
net.core.busy_read = 50

# --- 端口范围 ---
net.ipv4.ip_local_port_range = 10240 65535

# --- ARP 缓存 (防止高并发时 ARP 表溢出) ---
net.ipv4.neigh.default.gc_thresh1 = 1024
net.ipv4.neigh.default.gc_thresh2 = 4096
net.ipv4.neigh.default.gc_thresh3 = 8192

# --- 其他 ---
net.ipv4.tcp_fastopen = 3
net.ipv4.tcp_mtu_probing = 1
EOF
}

# ===================== 系统/网卡优化 =====================
optimize_system(){
  echo
  echo -e "${BOLD}【系统与网卡深度优化】${NC}"
  line

  local nic
  nic="$(ip route show default 2>/dev/null | awk '/default/ {print $5; exit}')"
  [[ -z "$nic" ]] && nic="eth0"
  
  info "检测到主网卡: $nic"

  # 1. 增大网卡 Ring Buffer (rx/tx 4096)
  if cmd_exists ethtool; then
     info "尝试调整网卡 Ring Buffer..."
     # 很多虚拟网卡不支持调整，忽略错误
     ethtool -G "$nic" rx 4096 tx 4096 >/dev/null 2>&1 || true
     local rx_val=$(ethtool -g "$nic" 2>/dev/null | grep "RX:" | tail -1 | awk '{print $2}')
     if [[ "$rx_val" == "4096" ]]; then
         ok "网卡 Ring Buffer 已成功调整为 4096"
     else
         info "网卡不支持 Ring Buffer 调整或已是最大值 (当前: ${rx_val:-未知})"
     fi
     
     # 2. 开启多队列 RSS
     local cpu_cores=$(nproc)
     info "尝试开启多队列 RSS ($cpu_cores 队列)..."
     ethtool -L "$nic" combined "$cpu_cores" >/dev/null 2>&1 || true
  else
     warn "未找到 ethtool，跳过网卡硬件优化"
  fi
  
  # 3. 自动安装并启用 irqbalance
  if ! cmd_exists irqbalance; then
      info "正在安装 irqbalance (平衡网卡中断)..."
      if cmd_exists apt-get; then
          apt-get update -y >/dev/null 2>&1
          apt-get install -y irqbalance >/dev/null 2>&1 || warn "irqbalance 安装失败"
      elif cmd_exists yum; then
          yum install -y irqbalance >/dev/null 2>&1 || warn "irqbalance 安装失败"
      fi
  fi
  
  if cmd_exists irqbalance; then
      # 尝试启动
      systemctl enable --now irqbalance >/dev/null 2>&1 || true
      if systemctl is-active irqbalance >/dev/null 2>&1; then
          ok "irqbalance 服务已运行"
      fi
  fi
  
  # 4. 提高文件描述符限制
  info "正在优化文件描述符限制 (ulimit)..."
  if grep -q "soft nofile" /etc/security/limits.conf; then
      sed -i '/soft nofile/d' /etc/security/limits.conf
      sed -i '/hard nofile/d' /etc/security/limits.conf
  fi
  echo "* soft nofile 655350" >> /etc/security/limits.conf
  echo "* hard nofile 655350" >> /etc/security/limits.conf
  echo "root soft nofile 655350" >> /etc/security/limits.conf
  echo "root hard nofile 655350" >> /etc/security/limits.conf
  ulimit -n 655350 >/dev/null 2>&1 || true
  ok "文件描述符限制已提升至 655350 (需重登录生效)"
}

# ===================== 应用配置 =====================
apply_optimize(){
  echo
  echo -e "${BOLD}【应用优化配置】${NC}"
  line

  mkdir -p "$BACKUP_DIR"
  
  # 1. 备份现有配置
  if [[ -f "$CONFIG_FILE" ]]; then
    cp "$CONFIG_FILE" "${BACKUP_DIR}/config_backup_$(date +%F_%H%M%S).conf"
    info "已备份现有配置到 $BACKUP_DIR"
  fi

  # 2. 生成新配置
  info "正在生成优化配置文件: $CONFIG_FILE"
  generate_config > "$CONFIG_FILE"

  # 3. 应用配置 (忽略错误，因为容器内部分参数可能只读)
  info "正在应用 sysctl 参数..."
  # 使用 -e 忽略未知键错误 (容器常见)
  if sysctl -p "$CONFIG_FILE" >/dev/null 2>&1; then
     ok "sysctl 应用成功"
  else
     warn "sysctl 应用部分失败 (正常现象，LXC 容器限制)"
     # 尝试逐行应用以显示具体成功项
     info "尝试逐行应用关键参数..."
     while read -r param; do
        [[ "$param" =~ ^# ]] && continue
        [[ -z "$param" ]] && continue
        sysctl -w "$param" >/dev/null 2>&1 || true
     done < "$CONFIG_FILE"
     ok "已尽可能应用所有允许的参数"
  fi
  
  # 4. 执行系统级优化
  optimize_system

  # 5. 验证
  local current_cc=$(sysctl -n net.ipv4.tcp_congestion_control 2>/dev/null)
  local current_fwd=$(sysctl -n net.ipv4.ip_forward 2>/dev/null)
  
  echo
  echo "--- 状态验证 ---"
  if [[ "$current_fwd" == "1" ]]; then ok "IP 转发: 开启"; else err "IP 转发: 未开启"; fi
  if [[ "$current_cc" == "bbr" ]]; then ok "拥塞控制: BBR"; else warn "拥塞控制: $current_cc"; fi
  
  line
  ok "NAT 优化完成！"
    if [[ "$virt_type" =~ lxc|docker ]]; then
     echo
     echo -e "${YELLOW}提示：在 LXC/Proxmox 环境下，强烈建议在宿主机也开启 BBR 并放开 cgroup 限制，以获得最佳效果。${NC}"
  fi
}

# ===================== 还原配置 =====================
restore_config(){
  echo
  echo -e "${BOLD}【还原默认配置】${NC}"
  line
  
  if [[ -f "$CONFIG_FILE" ]]; then
    rm -f "$CONFIG_FILE"
    info "已删除配置文件 $CONFIG_FILE"
    info "正在重载系统默认配置..."
    sysctl --system >/dev/null 2>&1 || true
    ok "已还原系统默认值"
  else
    warn "未找到优化配置文件，无需还原"
  fi
}

# ===================== 主菜单 =====================
main_menu(){
  clear
  echo -e "${BOLD}${BLUE}"
  echo "╔══════════════════════════════════════════════════════╗"
  echo "║         NAT 服务器专用优化脚本 (LXC/Container)       ║"
  echo "╚══════════════════════════════════════════════════════╝"
  echo -e "${NC}"
  echo "1) 执行预检查"
  echo "2) 应用 NAT 优化配置"
  echo "3) 还原默认配置"
  echo "0) 退出"
  line
  read -rp "请输入选项: " choice
  case "$choice" in
    1) precheck; read -p "按 Enter 继续..." ;;
    2) precheck; apply_optimize; read -p "按 Enter 继续..." ;;
    3) restore_config; read -p "按 Enter 继续..." ;;
    0) exit 0 ;;
    *) warn "无效选项"; sleep 1; main_menu ;;
  esac
  main_menu
}

# 入口
need_root
main_menu
